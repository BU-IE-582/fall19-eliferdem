{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecemnaz Bay - 2019702015\n",
    "\n",
    "\n",
    "Elif Emine Erdem - 2019702045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import poisson  \n",
    "from scipy.interpolate import *\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv(R'C:matches.csv')\n",
    "stats = pd.read_csv(R'C:stats.csv')\n",
    "bets = pd.read_csv(R'C:bets.csv')\n",
    "elo = pd.read_csv(R'C:Elo.txt')\n",
    "fifa = pd.read_csv(R'C:Fifa.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches_data_preprocessing(matches, stats,  LEAGUE_ID = 148):\n",
    "    \n",
    "    ProcessedData = matches\n",
    "    ProcessedStats =stats\n",
    "    ProcessedData = ProcessedData[ProcessedData.match_status == 'Finished']\n",
    "    ProcessedData = ProcessedData[ProcessedData.league_id == LEAGUE_ID]\n",
    "    ProcessedData = ProcessedData.drop_duplicates(subset='match_id', keep='first')\n",
    "    ProcessedData['total_score'] = ProcessedData['match_hometeam_score'] + ProcessedData['match_awayteam_score']\n",
    "    \n",
    "    conditions = [\n",
    "    (ProcessedData['match_hometeam_score'] - ProcessedData['match_awayteam_score'] == 0),\n",
    "    (ProcessedData['match_hometeam_score'] - ProcessedData['match_awayteam_score'] > 0),\n",
    "    (ProcessedData['match_hometeam_score'] - ProcessedData['match_awayteam_score'] < 0)]\n",
    "    choices = ['0', '1', '2']\n",
    "    \n",
    "    ProcessedData['Match_Result_Flag'] = np.select(conditions, choices, default='Null')\n",
    "    \n",
    "    ProcessedData = ProcessedData.merge(ProcessedStats, how='left', left_on='match_id', right_on='match_id', \\\n",
    "                            suffixes=(False, False))[ProcessedData.columns.tolist() \\\n",
    "                            + ['home_CornerKicks','home_ShotsonGoal','away_CornerKicks','away_ShotsonGoal']]\n",
    "    \n",
    " \n",
    "    \n",
    "    return ProcessedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def details_data_preprocessing(bets, matches, bets_type =  ['odd_1','odd_2','odd_x'], remove_bookmaker = [] , RemoveOlderThan = 2592000):\n",
    "    \n",
    "    ProcessedBets =  bets\n",
    "    remove_bookmaker  = ProcessedBets[['odd_bookmakers', 'value']].groupby(['odd_bookmakers'])['value'] \\\n",
    "                             .count() \\\n",
    "                             .reset_index(name='count') \\\n",
    "                             .sort_values(['count'], ascending=True) \\\n",
    "                             .head(5)\n",
    "\n",
    "    ProcessedBets = ProcessedBets.drop_duplicates(subset=['match_id','odd_bookmakers', 'variable', 'odd_epoch'], keep='first')\n",
    "    ProcessedBets = ProcessedBets[ProcessedBets['variable'].isin(bets_type)]\n",
    "    ProcessedBets = ProcessedBets.merge(matches,\n",
    "                                    how='left', left_on='match_id', right_on='match_id'\n",
    "                                    , suffixes=(False, False))[ProcessedBets.columns.tolist() \\\n",
    "                            + ['epoch']]\n",
    "    ProcessedBets = ProcessedBets [ProcessedBets['odd_epoch'] - ProcessedBets['epoch']<= 2592000  ]\n",
    "    ProcessedBets = ProcessedBets[~ProcessedBets['odd_bookmakers'].isin(remove_bookmaker)]\n",
    "    bets_pivot = pd.pivot_table(ProcessedBets,index=['match_id','odd_bookmakers','odd_epoch'] ,columns='variable',values='value').reset_index()\n",
    "    bets_pivot['prob_odd_1'] = 1/bets_pivot['odd_1']\n",
    "    bets_pivot['prob_odd_x'] = 1/bets_pivot['odd_x']\n",
    "    bets_pivot['prob_odd_2'] = 1/bets_pivot['odd_2']\n",
    "    \n",
    "    return bets_pivot\n",
    "    \n",
    "\n",
    "                             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_last_matches(data, nmatch=5):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    hometeam_exact_last_3 = []\n",
    "    hometeam_exact_last_5 = []\n",
    "    awayteam_exact_last_3 = []\n",
    "    awayteam_exact_last_5 = []\n",
    "    home_shots_3 = []\n",
    "    home_shots_5 = []\n",
    "    away_shots_3 = []\n",
    "    away_shots_5 = []\n",
    "    home_corner_3 = []\n",
    "    home_corner_5 = []\n",
    "    away_corner_3 = []\n",
    "    away_corner_5 = []\n",
    "    match_id = []\n",
    "    for i in data['match_hometeam_id'].unique():\n",
    "        data_created = data[data['match_hometeam_id']==i]\n",
    "        for y in data_created['epoch']:\n",
    "            data_epoch = data_created[data_created['epoch'] <= y ]\n",
    "            data_last5 = data_epoch.sort_values(by=['epoch'],  ascending=False).head(nmatch)\n",
    "            data_last3 = data_epoch.sort_values(by=['epoch'],  ascending=False).head(3)\n",
    "            hometeam_exact_last_3.append(data_last3['match_hometeam_score'].mean())\n",
    "            hometeam_exact_last_5.append(data_last5['match_hometeam_score'].mean())\n",
    "            match_id.append(data_created[data_created['epoch'] == y ]['match_id'].values[0])\n",
    "    \n",
    "    for i in data['match_awayteam_id'].unique():\n",
    "        data_created = data[data['match_awayteam_id']==i]\n",
    "        for y in data_created['epoch']:\n",
    "            data_epoch = data_created[data_created['epoch'] <= y ]\n",
    "            data_last5 = data_epoch.sort_values(by=['epoch'],  ascending=False).head(nmatch)\n",
    "            data_last3 = data_epoch.sort_values(by=['epoch'],  ascending=False).head(3)\n",
    "            awayteam_exact_last_3.append(data_last3['match_awayteam_score'].mean())\n",
    "            awayteam_exact_last_5.append(data_last5['match_awayteam_score'].mean())\n",
    "            \n",
    "    for i in data['match_awayteam_id'].unique():\n",
    "        data_created = data[data['match_awayteam_id']==i]\n",
    "        for y in data_created['epoch']:\n",
    "            data_epoch = data_created[data_created['epoch'] <= y ]\n",
    "            data_last5 = data_epoch.sort_values(by=['epoch'],  ascending=False).head(nmatch)\n",
    "            data_last3 = data_epoch.sort_values(by=['epoch'],  ascending=False).head(3)\n",
    "            home_shots_3.append(data_last3['home_ShotsonGoal'].mean())\n",
    "            home_shots_5.append(data_last5['home_ShotsonGoal'].mean())\n",
    "    \n",
    "    for i in data['match_awayteam_id'].unique():\n",
    "        data_created = data[data['match_awayteam_id']==i]\n",
    "        for y in data_created['epoch']:\n",
    "            data_epoch = data_created[data_created['epoch'] <= y ]\n",
    "            data_last5 = data_epoch.sort_values(by=['epoch'],  ascending=False).head(nmatch)\n",
    "            data_last3 = data_epoch.sort_values(by=['epoch'],  ascending=False).head(3)\n",
    "            away_shots_3.append(data_last3['away_ShotsonGoal'].mean())\n",
    "            away_shots_5.append(data_last5['away_ShotsonGoal'].mean())\n",
    "            \n",
    "    for i in data['match_awayteam_id'].unique():\n",
    "        data_created = data[data['match_awayteam_id']==i]\n",
    "        for y in data_created['epoch']:\n",
    "            data_epoch = data_created[data_created['epoch'] <= y ]\n",
    "            data_last5 = data_epoch.sort_values(by=['epoch'],  ascending=False).head(nmatch)\n",
    "            data_last3 = data_epoch.sort_values(by=['epoch'],  ascending=False).head(3)\n",
    "            home_corner_3.append(data_last3['home_CornerKicks'].mean())\n",
    "            home_corner_5.append(data_last5['home_CornerKicks'].mean())\n",
    "    \n",
    "    for i in data['match_awayteam_id'].unique():\n",
    "        data_created = data[data['match_awayteam_id']==i]\n",
    "        for y in data_created['epoch']:\n",
    "            data_epoch = data_created[data_created['epoch'] <= y ]\n",
    "            data_last5 = data_epoch.sort_values(by=['epoch'],  ascending=False).head(nmatch)\n",
    "            data_last3 = data_epoch.sort_values(by=['epoch'],  ascending=False).head(3)\n",
    "            away_corner_3.append(data_last3['away_CornerKicks'].mean())\n",
    "            away_corner_5.append(data_last5['away_CornerKicks'].mean())\n",
    "            \n",
    "            \n",
    "    df['hometeam_exact_last_3'] = hometeam_exact_last_3\n",
    "    df['hometeam_exact_last_5'] = hometeam_exact_last_5\n",
    "    df['awayteam_exact_last_3'] = awayteam_exact_last_3\n",
    "    df['awayteam_exact_last_5'] = awayteam_exact_last_5\n",
    "    df['home_shots_3'] = home_shots_3\n",
    "    df['home_shots_5'] = home_shots_5\n",
    "    df['away_shots_3'] = away_shots_3\n",
    "    df['away_shots_5'] = away_shots_5\n",
    "    df['home_corner_3'] = home_corner_3\n",
    "    df['home_corner_5'] = home_corner_5\n",
    "    df['away_corner_3'] = away_corner_3\n",
    "    df['away_corner_5'] = away_corner_5\n",
    "    df['match_id'] = match_id\n",
    "    \n",
    "    \n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_total_score(data):\n",
    "    df_total = pd.DataFrame()\n",
    "    \n",
    "    for i in  data['match_id']:\n",
    "        a = data[data['match_id']==i][['match_hometeam_id', 'match_awayteam_id', 'epoch', 'match_id']]\n",
    "        identical_matches = data[(data['epoch']<a['epoch'].values[0]) & \\\n",
    "                        ((data['match_hometeam_id'] == a['match_hometeam_id'].values[0])| \\\n",
    "                        (data['match_hometeam_id'] == a['match_awayteam_id'].values[0])) & \\\n",
    "                        ((data['match_awayteam_id'] == a['match_awayteam_id'].values[0]) | \\\n",
    "                        (data['match_awayteam_id'] == a['match_hometeam_id'].values[0]))]\n",
    "        a['prev_match_avg_score'] =  identical_matches['total_score'].mean()\n",
    "\n",
    "        df_total = df_total.append(a)\n",
    "        \n",
    "    return (df_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matches_data_preprocessing(matches, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matches.merge (elo, how='left', left_on = ['match_awayteam_id'], right_on = ['team_id'],suffixes = ('_away','_home'))\n",
    "matches = matches.merge (elo, how='left', left_on = ['match_hometeam_id'], right_on = ['team_id'],suffixes = ('_away','_home'))\n",
    "matches = matches.merge (fifa, how='left', left_on = ['match_awayteam_id'], right_on = ['team_id'],suffixes = ('_away','_home'))\n",
    "matches = matches.merge (fifa, how='left', left_on = ['match_hometeam_id'], right_on = ['team_id'],suffixes = ('_away','_home'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['rank_away', 'team_away', 'team_id_away', 'rank_home', 'team_home','team_id_home', 'team_id_away', 'team_away',  'team_id_home', 'team_home']\n",
    "matches = matches.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds = details_data_preprocessing(bets,matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_featured_first = feature_extraction_last_matches(matches, nmatch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_featured_second = feature_extraction_total_score(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.merge(matches_featured_second, matches_featured_first, how='left', on='match_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds =odds[['match_id', 'prob_odd_1', 'prob_odd_x', 'prob_odd_2']].groupby(['match_id'])[['prob_odd_1', 'prob_odd_x', 'prob_odd_2']].mean().reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_hometeam_id</th>\n",
       "      <th>match_awayteam_id</th>\n",
       "      <th>epoch</th>\n",
       "      <th>match_id</th>\n",
       "      <th>prev_match_avg_score</th>\n",
       "      <th>hometeam_exact_last_3</th>\n",
       "      <th>hometeam_exact_last_5</th>\n",
       "      <th>awayteam_exact_last_3</th>\n",
       "      <th>awayteam_exact_last_5</th>\n",
       "      <th>home_shots_3</th>\n",
       "      <th>home_shots_5</th>\n",
       "      <th>away_shots_3</th>\n",
       "      <th>away_shots_5</th>\n",
       "      <th>home_corner_3</th>\n",
       "      <th>home_corner_5</th>\n",
       "      <th>away_corner_3</th>\n",
       "      <th>away_corner_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2619</td>\n",
       "      <td>2614</td>\n",
       "      <td>1505561400</td>\n",
       "      <td>13331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2623</td>\n",
       "      <td>2626</td>\n",
       "      <td>1505570400</td>\n",
       "      <td>13329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.2</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.2</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2621</td>\n",
       "      <td>2629</td>\n",
       "      <td>1505570400</td>\n",
       "      <td>13327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2654</td>\n",
       "      <td>2641</td>\n",
       "      <td>1505570400</td>\n",
       "      <td>13456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.4</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2616</td>\n",
       "      <td>2617</td>\n",
       "      <td>1505651400</td>\n",
       "      <td>13324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_hometeam_id  match_awayteam_id       epoch  match_id  \\\n",
       "0               2619               2614  1505561400     13331   \n",
       "1               2623               2626  1505570400     13329   \n",
       "2               2621               2629  1505570400     13327   \n",
       "3               2654               2641  1505570400     13456   \n",
       "4               2616               2617  1505651400     13324   \n",
       "\n",
       "   prev_match_avg_score  hometeam_exact_last_3  hometeam_exact_last_5  \\\n",
       "0                   NaN                    0.0                    0.0   \n",
       "1                   NaN                    0.0                    0.0   \n",
       "2                   NaN                    1.0                    1.0   \n",
       "3                   NaN                    0.0                    0.0   \n",
       "4                   NaN                    0.0                    0.0   \n",
       "\n",
       "   awayteam_exact_last_3  awayteam_exact_last_5  home_shots_3  home_shots_5  \\\n",
       "0               1.000000                    1.0      3.000000           3.0   \n",
       "1               1.333333                    1.2      5.666667           6.0   \n",
       "2               2.000000                    2.2      5.000000           5.0   \n",
       "3               1.333333                    1.4      4.333333           4.2   \n",
       "4               1.000000                    0.6      5.666667           4.4   \n",
       "\n",
       "   away_shots_3  away_shots_5  home_corner_3  home_corner_5  away_corner_3  \\\n",
       "0      4.000000           4.0       5.000000            5.0       5.000000   \n",
       "1      4.666667           3.8       4.000000            7.2      10.666667   \n",
       "2      7.666667           7.2       3.333333            3.4       7.666667   \n",
       "3      3.000000           2.6       7.666667            6.6       5.000000   \n",
       "4      2.666667           2.4       7.000000            6.4       3.666667   \n",
       "\n",
       "   away_corner_5  \n",
       "0            5.0  \n",
       "1            7.2  \n",
       "2            8.8  \n",
       "3            4.8  \n",
       "4            4.6  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = results.merge(matches, how='left', on=['match_id','match_hometeam_id', 'match_awayteam_id', 'epoch'], suffixes=(False, False))[results.columns.tolist() + ['Match_Result_Flag', 'elo_away',\n",
    "       'elo_home', 'ATT_away', 'MID_away', 'DEF_away', 'OVR_away', 'ATT_home',\n",
    "       'MID_home', 'DEF_home', 'OVR_home']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.merge(odds, how='left', on='match_id', suffixes=(False, False))[results.columns.tolist() + ['prob_odd_1', 'prob_odd_x', 'prob_odd_2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.fillna(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For rounds,  the data is splitted to train and test by date. For tuning the parameters  train_test_split is used. So test_size is 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   16.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned learning_rate = 0.001\n",
      "Tuned max_depth = 3\n",
      "Tuned n_estimators = 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(results.drop(columns = ['match_hometeam_id', 'match_awayteam_id', 'epoch', 'match_id']), \n",
    "                                                        results['Match_Result_Flag'], \n",
    "                                                        test_size=0.2)\n",
    "\n",
    "\n",
    "# Hyper Parameter Tuning\n",
    "\n",
    "# Random Forest HPT\n",
    "param_grid = {\n",
    "    'learning_rate':[0.001], ##, 0.005, 0.01, 0.05, 0.1, 0.15, 0.5], \n",
    "    'max_depth': [3, 5 ],##, 7, 9, 11, 13, 15],\n",
    "    'n_estimators':[100] ##, 200, 300, 400]\n",
    "}\n",
    "# Create a based model\n",
    "rf = GradientBoostingClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(results.drop(columns = ['match_hometeam_id', 'match_awayteam_id', 'epoch', 'match_id']),\n",
    "                results['Match_Result_Flag'])\n",
    "        \n",
    "grid_search.best_params_\n",
    "\n",
    "best_grid_rf = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Fitting the Model by Using the Best Parameters\n",
    "classifier = best_grid_rf\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "# Prediction\n",
    "y_pred = classifier.predict_proba(X_test)\n",
    "print('Tuned learning_rate = ' + str(grid_search.best_params_['learning_rate']))\n",
    "print('Tuned max_depth = ' + str(grid_search.best_params_['max_depth']))\n",
    "print('Tuned n_estimators = ' + str(grid_search.best_params_['n_estimators']))\n",
    "\n",
    "\n",
    "# Prediction\n",
    "y_pred_train = classifier.predict_proba(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rps(predictions, observed):\n",
    "    ncat = 3\n",
    "    npred = len(predictions)\n",
    "    rps = np.zeros(npred)\n",
    "\n",
    "    for x in range(0, npred):\n",
    "        obsvec = np.zeros(ncat)\n",
    "        obsvec[observed.iloc[x]-1] = 1\n",
    "        cumulative = 0\n",
    "        for i in range(1, ncat):\n",
    "            cumulative += (sum(predictions.iloc[x, 1:i]) - sum(obsvec[1:i])) ** 2\n",
    "            rps[x] = cumulative / (ncat-1)\n",
    "\n",
    "    return rps\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
